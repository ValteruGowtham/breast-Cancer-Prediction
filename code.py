# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IS0x5vXfDvzcCFThuZBOu8aoYQPq0m_1
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import confusion_matrix

df = pd.read_csv('data.csv')

df.info()

df.head()

df.shape

df.isnull().sum()

# handle null valuess
df_new=df.drop(['Unnamed: 32', 'id'], axis=1)

df_new.isnull().sum()

# converting categorical values to numerical values -> label encoder
df_new['diagnosis'] = LabelEncoder().fit_transform(df_new['diagnosis'])

#Correlation matrix
corr = df_new.corr()

import seaborn as sns
plt.figure(figsize=(10, 10))
sns.heatmap(corr, cmap='coolwarm', annot=True)
plt.title('correlation matrix')
plt.show()

#StandardScaler
scaler = StandardScaler()
df_i = scaler.fit_transform(df_new.drop('diagnosis', axis=1))

# feature importance

'''
coffecient = pd.Series(model.coef_[0])
features = df_new.drop(['diagnosis'], axis=1)

con = pd.Series(coffecient, index=features.columns)
plt.figure(figsize=(6,6))
con.sort_values().plot(kind='barh', color='skyblue')
plt.title('Feature Importance (Logistic Regression Coefficients)')
plt.xlabel('Coefficient Value')
plt.ylabel('Feature')
plt.grid(True)
plt.tight_layout()
plt.show()

X = df_i
y = df_new[['diagnosis']]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)

# Gridsearch params
param_grid = {
    'C': [0.01, 0.1, 1, 10, 100],
    'penalty': ['l1', 'l2'],
    'solver': ['liblinear']
}

grid = GridSearchCV(
    estimator=LogisticRegression(),
    param_grid=param_grid,
    cv=5,                   # 5-fold cross-validation
    scoring='accuracy',     # or 'f1', 'roc_auc'
    n_jobs=-1               # Use all CPU cores
)
grid.fit(X_train, y_train.values.ravel())

print("Best Parameters:", grid.best_params_)
print("Best Cross-Validation Score:", grid.best_score_)

model = LogisticRegression(
    C=grid.best_params_['C'],
    penalty=grid.best_params_['penalty'],
    solver=grid.best_params_['solver']
)

model.fit(X_train, y_train.values.ravel())

y_pred = model.predict(X_test)

## confusion matrix
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(4, 4))
sns.heatmap(cm, cmap='coolwarm', annot=True)
plt.title('confusion matrix')
plt.show()

from sklearn.metrics import classification_report, accuracy_score

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))



# saving the model using joblib
import joblib
joblib.dump(model, 'model.pkl')

